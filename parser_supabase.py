#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –ù–•–¢–ö —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è GitHub Actions
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ Supabase
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime
from typing import Optional, List, Dict
import time
import os
import hashlib

# === –ò–º–ø–æ—Ä—Ç –¥–ª—è Supabase ===
try:
    from supabase import create_client, Client

    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ supabase –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")


class NHTKLiveParser:
    def __init__(self):
        self.base_url = "https://—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ.–Ω—Ö—Ç–∫.—Ä—Ñ"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Connection': 'keep-alive'
        })

    def fetch_page(self, url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–±—ã—Å—Ç—Ä–æ–µ)"""
        try:
            response = self.session.get(url, timeout=10)
            response.encoding = 'utf-8'
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None

    def parse_schedule(self, html: str, source_url: str) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∏–∑ HTML"""
        soup = BeautifulSoup(html, 'html.parser')
        schedule_data = {
            "metadata": {
                "source_url": source_url,
                "parse_date": datetime.now().isoformat(),
                "group": "",
                "period": ""
            },
            "schedule": []
        }

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã
        group_text = soup.find(string=re.compile(r'–ì—Ä—É–ø–ø–∞\s+[\d\.–ø]+'))
        if group_text:
            schedule_data["metadata"]["group"] = group_text.strip().replace('–ì—Ä—É–ø–ø–∞', '').strip()

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞
        period_patterns = [
            r'–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∑–∞–Ω—è—Ç–∏–π.*?\d{4}\s*–≥\.?',
            r'\d+\s+\w+\s*‚Äî\s*\d+\s+\w+\s+\d{4}'
        ]
        for text in soup.find_all(string=True):
            for pattern in period_patterns:
                if re.search(pattern, str(text), re.IGNORECASE):
                    schedule_data["metadata"]["period"] = text.strip()
                    break

        schedule_data["schedule"] = self._parse_table(soup)
        return schedule_data

    def _parse_table(self, soup: BeautifulSoup) -> List[Dict]:
        lessons = []
        current_day = None

        for row in soup.find_all('tr'):
            cells = row.find_all(['td', 'th'])
            if not cells: continue

            cell_texts = [cell.get_text(strip=True) for cell in cells]
            full_text = ' '.join(cell_texts)

            day_match = re.match(
                r'^(–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫|–í—Ç–æ—Ä–Ω–∏–∫|–°—Ä–µ–¥–∞|–ß–µ—Ç–≤–µ—Ä–≥|–ü—è—Ç–Ω–∏—Ü–∞|–°—É–±–±–æ—Ç–∞|–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ),\s+\d+\s+\w+',
                full_text
            )
            if day_match:
                current_day = day_match.group(0)
                continue

            if any(kw in full_text for kw in ['–í—Ä–µ–º—è', '–ü—Ä–µ–¥–º–µ—Ç', '–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å', '–ê—É–¥.', '–ü—Ä–µ–ø–æ–¥.']):
                continue

            if current_day and len(cells) >= 4:
                lesson = self._parse_lesson_row(cells, current_day)
                if lesson:
                    lessons.append(lesson)
        return lessons

    def _parse_lesson_row(self, cells, day: str) -> Optional[Dict]:
        try:
            lesson = {
                "day": day, "lesson_number": None, "time": "", "subject": "",
                "subject_url": "", "teacher": "", "teacher_url": "",
                "room": "", "room_url": "", "subgroup": ""
            }

            for i, cell in enumerate(cells):
                text = cell.get_text(strip=True)
                link = cell.find('a', href=True)
                href = link['href'] if link else ""
                if href and not href.startswith('http'):
                    href = self.base_url + '/' + href.lstrip('/')

                # ‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–æ–º–µ—Ä–∞ –ø–∞—Ä—ã
                if i < 2 and re.match(r'^\s*[1-9]\s*$', text):
                    try:
                        lesson["lesson_number"] = int(text.strip())
                    except ValueError:
                        pass
                    continue

                # –í—Ä–µ–º—è
                if re.search(r'\d{1,2}:\d{2}‚Äì\d{1,2}:\d{2}', text):
                    lesson["time"] = text
                    # –ï—Å–ª–∏ –Ω–æ–º–µ—Ä –ø–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                    if lesson["lesson_number"] is None:
                        lesson["lesson_number"] = self._get_lesson_from_time(text)
                    continue

                # –ü—Ä–µ–¥–º–µ—Ç
                if link and 'do.nhtk-edu.ru' in href:
                    subject_clean = re.sub(r'\s+', ' ', text).strip()
                    subject_clean = re.sub(r'\s*–∫/–ø\s*', ' ', subject_clean).strip()
                    lesson["subject"] = subject_clean
                    lesson["subject_url"] = href
                    subgroup_match = re.search(r'\[(\d+\s*–ø/–≥)\]', text)
                    if subgroup_match:
                        lesson["subgroup"] = subgroup_match.group(1).strip()
                    continue

                # –ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å
                if link and '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ.–Ω—Ö—Ç–∫.—Ä—Ñ' in href and not lesson["teacher"]:
                    lesson["teacher"] = text
                    lesson["teacher_url"] = href
                    continue

                # –ê—É–¥–∏—Ç–æ—Ä–∏—è
                if re.match(r'^(\d{2,3}|—Å/[–∑–∫])$', text, re.IGNORECASE):
                    lesson["room"] = text
                    if link:
                        lesson["room_url"] = href
                    continue

            # –ï—Å–ª–∏ –ø—Ä–µ–¥–º–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ —Å—Å—ã–ª–∫—É, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ —Ç–µ–∫—Å—Ç—É
            if not lesson["subject"]:
                for cell in cells:
                    text = cell.get_text(strip=True)
                    if text and not re.match(r'^\d+$', text) and not re.search(r'\d{1,2}:\d{2}', text):
                        if not re.match(r'^(\d{2,3}|—Å/[–∑–∫])$', text, re.IGNORECASE):
                            if not lesson["subject"]:
                                lesson["subject"] = re.sub(r'\s+', ' ', text).strip()
                            elif not lesson["teacher"]:
                                lesson["teacher"] = text

            if not lesson["subject"] or not lesson["time"]:
                return None
            return lesson
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏: {e}")
            return None

    def _get_lesson_from_time(self, time: str) -> Optional[int]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–æ–º–µ—Ä –ø–∞—Ä—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞"""
        if not time:
            return None

        start_time = time.split('‚Äì')[0].strip() if '‚Äì' in time else time.split('-')[0].strip()

        time_map = {
            '8:30': 1, '08:30': 1,
            '9:00': 1, '09:00': 1,
            '10:15': 2, '10:30': 2,
            '12:00': 3, '12:30': 3,
            '14:00': 4, '14:30': 4,
            '16:00': 5, '16:30': 5,
            '18:00': 6, '18:30': 6,
        }

        return time_map.get(start_time)

    def save_to_json(self, data: Dict, filename: str = "nhtk_schedule.json") -> bool:
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON: {e}")
            return False

    def _get_data_hash(self, schedule: List[Dict]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ö—ç—à –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        sorted_data = json.dumps(schedule, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(sorted_data.encode('utf-8')).hexdigest()

    def check_data_changed(self, new_data: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç–µ–º, —á—Ç–æ –≤ –±–∞–∑–µ"""
        if not SUPABASE_AVAILABLE:
            return True

        try:
            url = os.getenv("SUPABASE_URL")
            key = os.getenv("SUPABASE_KEY")
            if not url or not key:
                return True

            supabase: Client = create_client(url, key)
            group_code = new_data.get("metadata", {}).get("group", "")

            if not group_code:
                return True

            response = supabase.table("schedule_items") \
                .select("data_hash") \
                .eq("group_code", group_code) \
                .order("parsed_at", desc=True) \
                .limit(1) \
                .execute()

            if not response.data:
                print("‚ÑπÔ∏è –í –±–∞–∑–µ –Ω–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
                return True

            old_hash = response.data[0].get("data_hash")
            new_hash = self._get_data_hash(new_data.get("schedule", []))

            if old_hash == new_hash:
                print("‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å (—Ö—ç—à —Å–æ–≤–ø–∞–¥–∞–µ—Ç)")
                return False
            else:
                print("üîÑ –î–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å")
                return True

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {e}")
            return True

    def save_to_supabase(self, data: Dict) -> bool:
        if not SUPABASE_AVAILABLE:
            return False

        try:
            url = os.getenv("SUPABASE_URL")
            key = os.getenv("SUPABASE_KEY")
            if not url or not key:
                return False

            supabase: Client = create_client(url, key)
            schedule_items = data.get("schedule", [])
            metadata = data.get("metadata", {})

            if not schedule_items:
                return False

            current_data_hash = self._get_data_hash(schedule_items)

            items_to_insert = []
            for item in schedule_items:
                items_to_insert.append({
                    "group_code": metadata.get("group", ""),
                    "period": metadata.get("period", ""),
                    "source_url": metadata.get("source_url", ""),
                    "day": item.get("day", ""),
                    "lesson_number": item.get("lesson_number"),  # –£–∂–µ int –∏–ª–∏ None
                    "time": item.get("time", ""),
                    "subject": item.get("subject", ""),
                    "subject_url": item.get("subject_url", ""),
                    "teacher": item.get("teacher", ""),
                    "teacher_url": item.get("teacher_url", ""),
                    "room": item.get("room", ""),
                    "room_url": item.get("room_url", ""),
                    "subgroup": item.get("subgroup", ""),
                    "parsed_at": datetime.now().isoformat(),
                    "data_hash": current_data_hash
                })

            # ‚úÖ –°–ù–ê–ß–ê–õ–ê —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
            print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã: {metadata.get('group', '')}")
            supabase.table("schedule_items").delete().eq("group_code", metadata.get("group")).execute()

            # ‚úÖ –ü–û–¢–û–ú –≤—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ
            response = supabase.table("schedule_items").insert(items_to_insert).execute()
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(items_to_insert)} –∑–∞–ø–∏—Å–µ–π –≤ Supabase")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Supabase: {e}")
            return False

    def parse_url(self, url: str, output_file: str = "nhtk_schedule.json",
                  upload_to_supabase: bool = True, is_scheduled: bool = False) -> bool:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        if '#–∑–∞–≥–æ–ª–æ–≤–æ–∫' not in url:
            url = url + '#–∑–∞–≥–æ–ª–æ–≤–æ–∫'

        html = self.fetch_page(url)
        if not html:
            return False

        print("üîç –ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è...")
        data = self.parse_schedule(html, source_url=url)

        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∑–∞–Ω—è—Ç–∏–π: {len(data['schedule'])}")

        self.save_to_json(data, output_file)

        if upload_to_supabase:
            # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–ª–∞–≥–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            force_update = os.getenv("FORCE_UPDATE") == 'true'

            if force_update:
                print("‚ö° FORCE_UPDATE: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö")
                has_changes = True
            else:
                has_changes = self.check_data_changed(data)

            if not has_changes:
                print("üí§ –î–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –ø—Ä–æ–ø—É—â–µ–Ω–∞")
                return True

            print("‚òÅÔ∏è –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Supabase...")
            return self.save_to_supabase(data)

        return True

    def get_schedule_summary(self, data: Dict) -> Dict:
        return {
            "group": data["metadata"]["group"],
            "total_lessons": len(data["schedule"]),
        }


if __name__ == "__main__":
    print("=" * 60)
    print("üéì –ü–∞—Ä—Å–µ—Ä –ù–•–¢–ö (Optimized for GitHub Actions)")
    print("=" * 60)

    parser = NHTKLiveParser()
    url = "https://—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ.–Ω—Ö—Ç–∫.—Ä—Ñ/09.07.13–ø1.html"

    has_keys = bool(os.getenv("SUPABASE_URL") and os.getenv("SUPABASE_KEY"))
    is_scheduled = os.getenv("IS_SCHEDULED") == 'true'

    print(f"üîë –ö–ª—é—á–∏ Supabase: {'–ù–∞–π–¥–µ–Ω—ã' if has_keys else '–ù–µ –Ω–∞–π–¥–µ–Ω—ã'}")
    print(f"üïí –¢–∏–ø –∑–∞–ø—É—Å–∫–∞: {'–ü–ª–∞–Ω–æ–≤—ã–π (Cron)' if is_scheduled else '–†—É—á–Ω–æ–π'}")

    success = parser.parse_url(
        url,
        "nhtk_schedule.json",
        upload_to_supabase=has_keys,
        is_scheduled=is_scheduled
    )

    if success:
        print("\n‚úÖ –ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
        exit(1)

    print("=" * 60)