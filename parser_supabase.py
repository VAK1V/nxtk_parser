#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –ù–•–¢–ö —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è GitHub Actions
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ Supabase
"""

import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime
from typing import Optional, List, Dict
import time
import os
import hashlib

# === –ò–º–ø–æ—Ä—Ç –¥–ª—è Supabase ===
try:
    from supabase import create_client, Client

    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ supabase –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")


class NHTKLiveParser:
    def __init__(self):
        self.base_url = "https://—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ.–Ω—Ö—Ç–∫.—Ä—Ñ"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Connection': 'keep-alive'
        })

    def fetch_page(self, url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–±—ã—Å—Ç—Ä–æ–µ)"""
        try:
            # ‚ö° –£–º–µ–Ω—å—à–∏–ª–∏ —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            response = self.session.get(url, timeout=10)
            response.encoding = 'utf-8'
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return None

    def parse_schedule(self, html: str, source_url: str) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∏–∑ HTML"""
        soup = BeautifulSoup(html, 'html.parser')
        schedule_data = {
            "metadata": {
                "source_url": source_url,
                "parse_date": datetime.now().isoformat(),
                "group": "",
                "period": ""
            },
            "schedule": []
        }

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã
        group_text = soup.find(string=re.compile(r'–ì—Ä—É–ø–ø–∞\s+[\d\.–ø]+'))
        if group_text:
            schedule_data["metadata"]["group"] = group_text.strip().replace('–ì—Ä—É–ø–ø–∞', '').strip()

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞
        period_patterns = [
            r'–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∑–∞–Ω—è—Ç–∏–π.*?\d{4}\s*–≥\.?',
            r'\d+\s+\w+\s*‚Äî\s*\d+\s+\w+\s+\d{4}'
        ]
        for text in soup.find_all(string=True):
            for pattern in period_patterns:
                if re.search(pattern, str(text), re.IGNORECASE):
                    schedule_data["metadata"]["period"] = text.strip()
                    break

        schedule_data["schedule"] = self._parse_table(soup)
        return schedule_data

    def _parse_table(self, soup: BeautifulSoup) -> List[Dict]:
        lessons = []
        current_day = None

        for row in soup.find_all('tr'):
            cells = row.find_all(['td', 'th'])
            if not cells: continue

            cell_texts = [cell.get_text(strip=True) for cell in cells]
            full_text = ' '.join(cell_texts)

            day_match = re.match(
                r'^(–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫|–í—Ç–æ—Ä–Ω–∏–∫|–°—Ä–µ–¥–∞|–ß–µ—Ç–≤–µ—Ä–≥|–ü—è—Ç–Ω–∏—Ü–∞|–°—É–±–±–æ—Ç–∞|–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ),\s+\d+\s+\w+',
                full_text
            )
            if day_match:
                current_day = day_match.group(0)
                continue

            if any(kw in full_text for kw in ['–í—Ä–µ–º—è', '–ü—Ä–µ–¥–º–µ—Ç', '–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å', '–ê—É–¥.', '–ü—Ä–µ–ø–æ–¥.']):
                continue

            if current_day and len(cells) >= 4:
                lesson = self._parse_lesson_row(cells, current_day)
                if lesson:
                    lessons.append(lesson)
        return lessons

    def _parse_lesson_row(self, cells, day: str) -> Optional[Dict]:
        try:
            lesson = {
                "day": day, "lesson_number": "", "time": "", "subject": "",
                "subject_url": "", "teacher": "", "teacher_url": "",
                "room": "", "room_url": "", "subgroup": ""
            }

            for i, cell in enumerate(cells):
                text = cell.get_text(strip=True)
                link = cell.find('a', href=True)
                href = link['href'] if link else ""
                if href and not href.startswith('http'):
                    href = self.base_url + '/' + href.lstrip('/')

                if i == 0 and re.match(r'^\d+$', text):
                    lesson["lesson_number"] = text
                    continue
                if re.search(r'\d{1,2}:\d{2}‚Äì\d{1,2}:\d{2}', text):
                    lesson["time"] = text
                    continue
                if link and 'do.nhtk-edu.ru' in href:
                    subject_clean = re.sub(r'\s+', ' ', text).strip()
                    subject_clean = re.sub(r'\s*–∫/–ø\s*', ' ', subject_clean).strip()
                    lesson["subject"] = subject_clean
                    lesson["subject_url"] = href
                    subgroup_match = re.search(r'\[(\d+\s*–ø/–≥)\]', text)
                    if subgroup_match:
                        lesson["subgroup"] = subgroup_match.group(1).strip()
                    continue
                if link and '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ.–Ω—Ö—Ç–∫.—Ä—Ñ' in href and not lesson["teacher"]:
                    lesson["teacher"] = text
                    lesson["teacher_url"] = href
                    continue
                if re.match(r'^(\d{2,3}|—Å/[–∑–∫])$', text, re.IGNORECASE):
                    lesson["room"] = text
                    if link: lesson["room_url"] = href
                    continue

            if not lesson["subject"]:
                for cell in cells:
                    text = cell.get_text(strip=True)
                    if text and not re.match(r'^\d+$', text) and not re.search(r'\d{1,2}:\d{2}', text):
                        if not re.match(r'^(\d{2,3}|—Å/[–∑–∫])$', text, re.IGNORECASE):
                            if not lesson["subject"]:
                                lesson["subject"] = re.sub(r'\s+', ' ', text).strip()
                            elif not lesson["teacher"]:
                                lesson["teacher"] = text

            if not lesson["subject"] or not lesson["time"]:
                return None
            return lesson
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏: {e}")
            return None

    def save_to_json(self, data: Dict, filename: str = "nhtk_schedule.json") -> bool:
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON: {e}")
            return False

    def _get_data_hash(self, schedule: List[Dict]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ö—ç—à –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –ø–æ—Ä—è–¥–æ–∫ –Ω–µ –≤–ª–∏—è–ª –Ω–∞ —Ö—ç—à
        sorted_data = json.dumps(schedule, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(sorted_data.encode('utf-8')).hexdigest()

    def check_data_changed(self, new_data: Dict) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ç–µ–º, —á—Ç–æ –≤ –±–∞–∑–µ.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –µ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è.
        """
        if not SUPABASE_AVAILABLE:
            return True  # –ï—Å–ª–∏ –Ω–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å

        try:
            url = os.getenv("SUPABASE_URL")
            key = os.getenv("SUPABASE_KEY")
            if not url or not key:
                return True

            supabase: Client = create_client(url, key)
            group_code = new_data.get("metadata", {}).get("group", "")

            if not group_code:
                return True

            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
            response = supabase.table("schedule_items") \
                .select("data_hash") \
                .eq("group_code", group_code) \
                .order("parsed_at", desc=True) \
                .limit(1) \
                .execute()

            if not response.data:
                print("‚ÑπÔ∏è –í –±–∞–∑–µ –Ω–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
                return True

            old_hash = response.data[0].get("data_hash")
            new_hash = self._get_data_hash(new_data.get("schedule", []))

            if old_hash == new_hash:
                print("‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å (—Ö—ç—à —Å–æ–≤–ø–∞–¥–∞–µ—Ç)")
                return False
            else:
                print("üîÑ –î–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å")
                return True

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {e}")
            return True  # –ü—Ä–∏ –æ—à–∏–±–∫–µ –ª—É—á—à–µ –æ–±–Ω–æ–≤–∏—Ç—å

    def save_to_supabase(self, data: Dict) -> bool:
        if not SUPABASE_AVAILABLE:
            return False

        try:
            url = os.getenv("SUPABASE_URL")
            key = os.getenv("SUPABASE_KEY")
            if not url or not key:
                return False

            supabase: Client = create_client(url, key)
            schedule_items = data.get("schedule", [])
            metadata = data.get("metadata", {})

            if not schedule_items:
                return False

            # –í—ã—á–∏—Å–ª—è–µ–º —Ö—ç—à –¥–ª—è –≤—Å–µ–π –ø–∞—á–∫–∏
            current_data_hash = self._get_data_hash(schedule_items)

            items_to_insert = []
            for item in schedule_items:
                lesson_num = None
                if item.get("lesson_number"):
                    try:
                        lesson_num = int(item["lesson_number"])
                    except (ValueError, TypeError):
                        lesson_num = None

                items_to_insert.append({
                    "group_code": metadata.get("group", ""),
                    "period": metadata.get("period", ""),
                    "source_url": metadata.get("source_url", ""),
                    "day": item.get("day", ""),
                    "lesson_number": lesson_num,
                    "time": item.get("time", ""),
                    "subject": item.get("subject", ""),
                    "subject_url": item.get("subject_url", ""),
                    "teacher": item.get("teacher", ""),
                    "teacher_url": item.get("teacher_url", ""),
                    "room": item.get("room", ""),
                    "room_url": item.get("room_url", ""),
                    "subgroup": item.get("subgroup", ""),
                    "parsed_at": datetime.now().isoformat(),
                    "data_hash": current_data_hash  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ö—ç—à
                })

            response = supabase.table("schedule_items").insert(items_to_insert).execute()
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(items_to_insert)} –∑–∞–ø–∏—Å–µ–π –≤ Supabase")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Supabase: {e}")
            return False

    def parse_url(self, url: str, output_file: str = "nhtk_schedule.json",
                  upload_to_supabase: bool = True, is_scheduled: bool = False) -> bool:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        if '#–∑–∞–≥–æ–ª–æ–≤–æ–∫' not in url:
            url = url + '#–∑–∞–≥–æ–ª–æ–≤–æ–∫'

        html = self.fetch_page(url)
        if not html:
            return False

        print("üîç –ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è...")
        data = self.parse_schedule(html, source_url=url)

        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∑–∞–Ω—è—Ç–∏–π: {len(data['schedule'])}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π JSON –≤—Å–µ–≥–¥–∞ (–¥–ª—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ)
        self.save_to_json(data, output_file)

        # –õ–æ–≥–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –æ–±–ª–∞–∫–æ
        if upload_to_supabase:
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ
            has_changes = self.check_data_changed(data)

            if not has_changes:
                print("üí§ –î–∞–Ω–Ω—ã–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –ø—Ä–æ–ø—É—â–µ–Ω–∞ (—ç–∫–æ–Ω–æ–º–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤)")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º True, —Ç–∞–∫ –∫–∞–∫ –æ—à–∏–±–∫–∞ –Ω–µ –ø—Ä–æ–∏–∑–æ—à–ª–∞, –ø—Ä–æ—Å—Ç–æ –Ω–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                return True

            # 2. –ï—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –µ—Å—Ç—å ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º
            print("‚òÅÔ∏è –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Supabase...")
            return self.save_to_supabase(data)

        return True

    def get_schedule_summary(self, data: Dict) -> Dict:
        summary = {
            "group": data["metadata"]["group"],
            "total_lessons": len(data["schedule"]),
        }
        return summary


if __name__ == "__main__":
    print("=" * 60)
    print("üéì –ü–∞—Ä—Å–µ—Ä –ù–•–¢–ö (Optimized for GitHub Actions)")
    print("=" * 60)

    parser = NHTKLiveParser()
    url = "https://—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ.–Ω—Ö—Ç–∫.—Ä—Ñ/09.07.13–ø1.html"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–π
    has_keys = bool(os.getenv("SUPABASE_URL") and os.getenv("SUPABASE_KEY"))
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–ª–∞–≥–∞ –ø–ª–∞–Ω–æ–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    is_scheduled = os.getenv("IS_SCHEDULED") == 'true'

    print(f"üîë –ö–ª—é—á–∏ Supabase: {'–ù–∞–π–¥–µ–Ω—ã' if has_keys else '–ù–µ –Ω–∞–π–¥–µ–Ω—ã'}")
    print(f"üïí –¢–∏–ø –∑–∞–ø—É—Å–∫–∞: {'–ü–ª–∞–Ω–æ–≤—ã–π (Cron)' if is_scheduled else '–†—É—á–Ω–æ–π'}")

    success = parser.parse_url(
        url,
        "nhtk_schedule.json",
        upload_to_supabase=has_keys,
        is_scheduled=is_scheduled
    )

    if success:
        print("\n‚úÖ –ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
        exit(1)  # –í–∞–∂–Ω–æ –¥–ª—è GitHub Actions: –∫–æ–¥ 1 –æ–∑–Ω–∞—á–∞–µ—Ç –æ—à–∏–±–∫—É

    print("=" * 60)